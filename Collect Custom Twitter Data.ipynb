{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6622b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from Twitter_functions import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9971ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Authentication/twitter_bearer_token.txt', 'r', encoding=\"utf8\") as f:\n",
    "    token = f.read()\n",
    "\n",
    "header = create_Twitter_headers(token)\n",
    "\n",
    "with open('Authentication/database_uri.txt', 'r', encoding=\"utf8\") as f:\n",
    "    uri = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d1dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkForRepliesToNews(tweetDict):\n",
    "    result = []\n",
    "    for i in tweetDict['data']:\n",
    "        reply = re.findall(\"(@[A-Za-z0-9]+)\", i['text'])\n",
    "\n",
    "        if any(x in ['@MothershipSG', '@straits_times', '@ChannelNewsAsia', '@YahooSG'] for x in reply):\n",
    "            result.append(i)\n",
    "\n",
    "    return result\n",
    "\n",
    "def getAndSaveReplyNRetweets(users, filterForNewsProvider, noUserId = True):\n",
    "    result = {}\n",
    "    \n",
    "    for i in users:\n",
    "        \n",
    "        if noUserId:\n",
    "            userID = getTwitterUserInfo(i, header)['data'][0]['id']\n",
    "            tweets = getTweetsByUserID(userID, header)\n",
    "        \n",
    "        else:\n",
    "            tweets = getTweetsLikedByUser(i, header)\n",
    "        \n",
    "        if filterForNewsProvider:\n",
    "            filterTweets = checkForRepliesToNews(tweets)\n",
    "            \n",
    "            if len(filterTweets) > 0:\n",
    "                \n",
    "                if noUserId:\n",
    "                    result[userID] = filterTweets\n",
    "                    \n",
    "                else:\n",
    "                    result[i] = filterTweets\n",
    "        \n",
    "        else:\n",
    "            if noUserId:\n",
    "                result[userID] = tweets['data']\n",
    "                \n",
    "            else:\n",
    "                result[i] = tweets['data']\n",
    "        \n",
    "    return result\n",
    "\n",
    "def getAndSaveLikedTweets(users, filterForNewsProvider, noUserId = True):\n",
    "    result = {}\n",
    "    \n",
    "    for i in users:\n",
    "        \n",
    "        if noUserId:\n",
    "            userID = getTwitterUserInfo(i, header)['data'][0]['id']\n",
    "            tweets = getTweetsLikedByUser(userID, header)\n",
    "            \n",
    "        else:\n",
    "            tweets = getTweetsLikedByUser(i, header)\n",
    "        \n",
    "        if filterForNewsProvider:\n",
    "            filterTweets = checkForRepliesToNews(tweets)\n",
    "            \n",
    "            if len(filterTweets) > 0:\n",
    "                \n",
    "                if noUserId:\n",
    "                    result[userID] = filterTweets\n",
    "                    \n",
    "                else:\n",
    "                    result[i] = filterTweets\n",
    "        \n",
    "        else:\n",
    "            if noUserId:\n",
    "                result[userID] = tweets['data']\n",
    "            \n",
    "            else:\n",
    "                result[i] = tweets['data']\n",
    "        \n",
    "    return result\n",
    "\n",
    "def getCommentsFromDBAndSave(conversationID, dbName, haveUserId = True):\n",
    "    result = {'data':[]}\n",
    "    \n",
    "    command = \"select * from %s where conversation_id = '%s';\" % (dbName, conversationID)\n",
    "    conn = psycopg2.connect(uri, sslmode='require')\n",
    "\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(command)\n",
    "        row = cur.fetchall()\n",
    "\n",
    "        for i in row:\n",
    "            resultDict = {}\n",
    "            resultDict['id'] = i[0]\n",
    "            resultDict['timestamp'] = i[1]\n",
    "            resultDict['reply_to'] = i[2]\n",
    "            resultDict['comment'] = i[3]\n",
    "            resultDict['social_media'] = i[4]\n",
    "            resultDict['head_id'] = i[5]\n",
    "            resultDict['conversation_id'] = i[6]\n",
    "            \n",
    "            if haveUserId:\n",
    "                resultDict['user_id'] = i[7]\n",
    "            \n",
    "            result['data'].append(resultDict)\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        return error\n",
    "    \n",
    "    return result\n",
    "\n",
    "def getCommentsFromDBAndSave_PHEME(conversationID, dbName, haveUserId = True):\n",
    "    result = {'data':[]}\n",
    "    \n",
    "    command = \"select * from %s where head_id = '%s';\" % (dbName, conversationID)\n",
    "    conn = psycopg2.connect(uri, sslmode='require')\n",
    "\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(command)\n",
    "        row = cur.fetchall()\n",
    "\n",
    "        for i in row:\n",
    "            resultDict = {}\n",
    "            resultDict['id'] = i[0]\n",
    "            resultDict['timestamp'] = i[1]\n",
    "            resultDict['reply_to'] = i[2]\n",
    "            resultDict['comment'] = i[3]\n",
    "            resultDict['head_id'] = i[4]\n",
    "            result['data'].append(resultDict)\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        return error\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc9b43c",
   "metadata": {},
   "source": [
    "# Case Study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e930d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs1_comments = getCommentsFromDBAndSave_PHEME('553553331671408641', 'pheme_dataset_for_analysis', False)\n",
    "\n",
    "with open('Collected Data/case_study_1_all_comments.json', 'w') as fp:\n",
    "    json.dump(cs1_comments, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d49d14",
   "metadata": {},
   "source": [
    "# Case Study 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be07e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs2_comments = getCommentsFromDBAndSave('1507922082683793408', 'comments_for_analysis', False)\n",
    "\n",
    "# with open('Collected Data/case_study_2_all_comments.json', 'w') as fp:\n",
    "#     json.dump(cs2_comments, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43e6eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suspectedBiasUsers = ['CardanoAdonis', 'PLafala', 'Erwin_Dawson', 'Coldcappuccino9', '_5andman_', 'Actarus_dEuphor', 'ResenT___', 'mkggoh', 'slowpokemax']\n",
    "\n",
    "# cs2_dataDict_1 = getAndSaveReplyNRetweets(suspectedBiasUsers, False)\n",
    "\n",
    "# with open('Collected Data/case_study_2_all_bias_users_retweet_replies.json', 'w') as fp:\n",
    "#     json.dump(cs2_dataDict_1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea67494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs2_dataDict_2 = getAndSaveReplyNRetweets(suspectedBiasUsers, True)\n",
    "\n",
    "# with open('Collected Data/case_study_2_all_bias_users_retweet_replies_news_providers_filter.json', 'w') as fp:\n",
    "#     json.dump(cs2_dataDict_2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84f6bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs2_dataDict_1_likes = getAndSaveLikedTweets(suspectedBiasUsers, False)\n",
    "\n",
    "# with open('Collected Data/case_study_2_all_potentially_bias_users_liked_tweets.json', 'w') as fp:\n",
    "#     json.dump(cs2_dataDict_1_likes, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abec1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs2_dataDict_2_likes = getAndSaveLikedTweets(suspectedBiasUsers, True)\n",
    "\n",
    "# with open('Collected Data/case_study_2_all_potentially_bias_users_liked_tweets_news_providers_filter.json', 'w') as fp:\n",
    "#     json.dump(cs2_dataDict_2_likes, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47425b5c",
   "metadata": {},
   "source": [
    "# Case Study 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "567a9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs3_comments = getCommentsFromDBAndSave('1522931750451617793', 'comments_for_analysis', True)\n",
    "\n",
    "# with open('Collected Data/case_study_3_all_comments.json', 'w') as fp:\n",
    "#     json.dump(cs3_comments, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f725cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suspectedBiasUsers = ['1531214377', '804973086567055360', '83822931', '3246610436', '1365682034551627779', \n",
    "#                       '1339037189565415425', '1499140477718872072', '1266607549245091840', '890795094256648192',\n",
    "#                       '1509197192459816962', '1422221555950518275']\n",
    "\n",
    "# cs3_dataDict_1 = getAndSaveReplyNRetweets(suspectedBiasUsers, False, False)\n",
    "\n",
    "# with open('Collected Data/case_study_3_all_bias_users_retweet_replies.json', 'w') as fp:\n",
    "#     json.dump(cs3_dataDict_1, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a423e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs3_dataDict_2 = getAndSaveReplyNRetweets(suspectedBiasUsers, True, False)\n",
    "\n",
    "# with open('Collected Data/case_study_3_all_bias_users_retweet_replies_news_providers_filter.json', 'w') as fp:\n",
    "#     json.dump(cs3_dataDict_2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6be595e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs3_dataDict_1_likes = getAndSaveLikedTweets(suspectedBiasUsers, False, False)\n",
    "\n",
    "# with open('Collected Data/case_study_3_all_potentially_bias_users_liked_tweets.json', 'w') as fp:\n",
    "#     json.dump(cs3_dataDict_1_likes, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a900af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs2_dataDict_3_likes = getAndSaveLikedTweets(suspectedBiasUsers, True, False)\n",
    "\n",
    "# with open('Collected Data/case_study_3_all_potentially_bias_users_liked_tweets_news_providers_filter.json', 'w') as fp:\n",
    "#     json.dump(cs2_dataDict_3_likes, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
